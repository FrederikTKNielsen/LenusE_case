{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/fni/Desktop/Python'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "display(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple_autoML_BinaryClass:\n",
    "    def __init__(self, data_path, target_column, model_type):\n",
    "        \"\"\"Sample AutoML API that deals with binary classification problems.\n",
    "        Args:\n",
    "            data_path (str): Location of your sample dataset - place it in the same location as the code.\n",
    "            target_column (str): Column you are trying to predict.\n",
    "            model_type (str): Options are linear_regression and random_forest. #Change\n",
    "            \n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.target_column = target_column\n",
    "        self.model_type = model_type\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.train_ = None\n",
    "        self.test_ = None \n",
    "        self.my_model = None #use this to store the model trained for ensample models\n",
    "        self.X_train_scaled = None\n",
    "        self.X_test_scaled = None\n",
    "        self.params = None\n",
    "\n",
    "\n",
    "    def preprocess(self):\n",
    "        df = pd.read_csv(self.data_path)\n",
    "        columns = df.columns\n",
    "        if self.target_column not in columns:\n",
    "            raise ValueError(\"Target column not present in dataset\")\n",
    "        X = df.drop([self.target_column], axis = 1) \n",
    "        y = df[self.target_column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 42)\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.X_train_scaled = StandardScaler().fit_transform(X_train)\n",
    "        self.X_test_scaled = StandardScaler().fit_transform(X_test)\n",
    "        \n",
    "    def train(self):\n",
    "        model_types = ['MultinomialNB', 'LogisticRegression','KNeighborsClassifier','LinearSVC',\\\n",
    "                      'DecisionTreeClassifier','BaggingClassifier','AdaBoostClassifier'\\\n",
    "                      ,'RandomForestClassifier','SGDClassifier'] #Change\n",
    "        if self.model_type not in model_types:\n",
    "            raise ValueError(f\"Enter a model type that is supported from the following list: {model_types}\")\n",
    "\n",
    "        if self.model_type == \"MultinomialNB\":\n",
    "            #Model Creation for MultinomialNB\n",
    "            model_ = MultinomialNB()\n",
    "            model_.fit(self.X_train,self.y_train)\n",
    "            params_=model_.get_params()\n",
    "            #Model prediction\n",
    "            train = model_.score(self.X_train_scaled,self.y_train)\n",
    "            test = model_.score(self.X_test_scaled, self.y_test)\n",
    "\n",
    "        elif self.model_type == \"LogisticRegression\": \n",
    "            #Model Creation for LogisticRegression\n",
    "            model_ = LogisticRegression(max_iter=550, tol=0.1, C=0.01,n_jobs=20)\n",
    "            model_.fit(self.X_train_scaled,self.y_train)\n",
    "            params_=model_.get_params()\n",
    "            #Model prediction\n",
    "            train = model_.score(self.X_train_scaled,self.y_train)\n",
    "            test = model_.score(self.X_test_scaled, self.y_test)\n",
    "            \n",
    "        elif self.model_type == \"SGDClassifier\": \n",
    "            #Model Creation for LogisticRegression\n",
    "            model_ = SGDClassifier(alpha = 0.001)\n",
    "            model_.fit(self.X_train_scaled,self.y_train)\n",
    "            params_=model_.get_params()\n",
    "            #Model prediction\n",
    "            train = model_.score(self.X_train_scaled,self.y_train)\n",
    "            test = model_.score(self.X_test_scaled, self.y_test)\n",
    "        \n",
    "        elif self.model_type == \"KNeighborsClassifier\": \n",
    "            #Model Creation for KNeighborsClassifier\n",
    "            model_ = KNeighborsClassifier(algorithm = 'brute', n_jobs=-1)\n",
    "            model_.fit(self.X_train,self.y_train)\n",
    "            params_=model_.get_params()\n",
    "            #Model prediction\n",
    "            train = model_.score(self.X_train_scaled,self.y_train)\n",
    "            test = model_.score(self.X_test_scaled, self.y_test)\n",
    "            \n",
    "        elif self.model_type == \"LinearSVC\": \n",
    "            #Model Creation for LinearSVC\n",
    "            model_=LinearSVC(C=0.0001)\n",
    "            model_.fit(self.X_train,self.y_train)\n",
    "            params_=model_.get_params()\n",
    "            #Model prediction\n",
    "            train = model_.score(self.X_train,self.y_train)\n",
    "            test = model_.score(self.X_test, self.y_test)\n",
    "            \n",
    "        elif self.model_type == \"DecisionTreeClassifier\": \n",
    "            #Model Creation for DecisionTreeClassifier\n",
    "            model_=DecisionTreeClassifier()\n",
    "            model_.fit(self.X_train,self.y_train)\n",
    "            params_=model_.get_params()\n",
    "            #Model prediction\n",
    "            train = model_.score(self.X_train,self.y_train)\n",
    "            test = model_.score(self.X_test, self.y_test)            \n",
    "            \n",
    "        elif self.model_type == \"BaggingClassifier\": \n",
    "            #Model Creation for BaggingClassifier\n",
    "            model_=BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=10)\n",
    "            model_.fit(self.X_train,self.y_train)\n",
    "            params_=model_.get_params()\n",
    "            #Model prediction\n",
    "            train = model_.score(self.X_train,self.y_train)\n",
    "            test = model_.score(self.X_test, self.y_test)\n",
    "        \n",
    "        elif self.model_type == \"AdaBoostClassifier\": \n",
    "            #Model Creation for AdaBoostClassifier\n",
    "            model_=AdaBoostClassifier(DecisionTreeClassifier(min_samples_split=10,max_depth=4),\\\n",
    "                                      n_estimators=10,learning_rate=0.6)\n",
    "            model_.fit(self.X_train,self.y_train)\n",
    "            params_=model_.get_params()\n",
    "            #Model prediction\n",
    "            train = model_.score(self.X_train,self.y_train)\n",
    "            test = model_.score(self.X_test, self.y_test)\n",
    "            \n",
    "        elif self.model_type == \"RandomForestClassifier\": \n",
    "            #Model Creation for RandomForestClassifier\n",
    "            model_=RandomForestClassifier(n_estimators=100, max_depth=20)\n",
    "            model_.fit(self.X_train,self.y_train) \n",
    "            params_=model_.get_params()\n",
    "            #Model prediction\n",
    "            train = model_.score(self.X_train,self.y_train)\n",
    "            test = model_.score(self.X_test, self.y_test)\n",
    "            \n",
    "        self.train_ = train \n",
    "        self.test_ = test\n",
    "        self.my_model = model_\n",
    "        self.params = params_\n",
    "\n",
    "    def explain(self):\n",
    "        if self.model_type == \"LogisticRegression\" : #Change\n",
    "            #return print(pd.DataFrame(zip(self.X_train.columns, np.transpose(self.my_model.coef_)), columns=['features', 'coef']))\n",
    "            return f\"{pd.DataFrame(zip(self.X_train.columns, np.transpose(self.my_model.coef_)), columns=['features', 'coef'])},\\n intercept: {self.my_model.intercept_}\" #Change\n",
    "        \n",
    "        elif self.model_type == \"DecisionTreeClassifier\" :\n",
    "            sorted_feature_weight_idxes = np.argsort(self.my_model.feature_importances_)[::-1]\n",
    "            most_important_features = np.take_along_axis(np.array(self.X_train.columns.tolist()),sorted_feature_weight_idxes, axis=0)\n",
    "            most_important_weights = np.take_along_axis(np.array(self.my_model.feature_importances_), sorted_feature_weight_idxes, axis=0)\n",
    "            return plt.barh(most_important_features[::-1], most_important_weights[::-1])\n",
    "        \n",
    "        elif self.model_type == \"AdaBoostClassifier\" :\n",
    "            sorted_feature_weight_idxes = np.argsort(self.my_model.feature_importances_)[::-1]\n",
    "            most_important_features = np.take_along_axis(np.array(self.X_train.columns.tolist()),sorted_feature_weight_idxes, axis=0)\n",
    "            most_important_weights = np.take_along_axis(np.array(self.my_model.feature_importances_), sorted_feature_weight_idxes, axis=0)\n",
    "            return plt.barh(most_important_features[::-1], most_important_weights[::-1])\n",
    "        \n",
    "        elif self.model_type == \"RandomForestClassifier\" :\n",
    "            sorted_feature_weight_idxes = np.argsort(self.my_model.feature_importances_)[::-1]\n",
    "            most_important_features = np.take_along_axis(np.array(self.X_train.columns.tolist()),sorted_feature_weight_idxes, axis=0)\n",
    "            most_important_weights = np.take_along_axis(np.array(self.my_model.feature_importances_), sorted_feature_weight_idxes, axis=0)\n",
    "            return plt.barh(most_important_features[::-1], most_important_weights[::-1])\n",
    "        \n",
    "\n",
    "            \n",
    "        else:\n",
    "            return f\" This model can not be explained: {self.model_type}\" #Change\n",
    "    \n",
    "    \n",
    "    def logModelInfo(self):\n",
    "        if self.model_type == \"KNeighborsClassifier\": \n",
    "            modelDetails = {\n",
    "            \"ModelType\": self.model_type,\n",
    "            \"train_score\": self.train_, \n",
    "            \"test_score\": self.test_ ,\n",
    "            \"knn_shape\": self.X_train.shape,\n",
    "            \"params\": self.params\n",
    "            }\n",
    "            return modelDetails\n",
    "        else: \n",
    "            modelDetails = {\n",
    "            \"ModelType\": self.model_type,\n",
    "            \"train_score\": self.train_, \n",
    "            \"test_score\": self.test_,\n",
    "            \"params\": self.params\n",
    "            }\n",
    "            return modelDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelType': 'RandomForestClassifier', 'train_score': 0.9915730337078652, 'test_score': 0.8379888268156425, 'params': {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}}\n",
      "<BarContainer object of 12 artists>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    auto_model = Simple_autoML_BinaryClass(\"data/knn.csv\", \"converted\", \"RandomForestClassifier\")\n",
    "    auto_model.preprocess()\n",
    "    auto_model.train()\n",
    "    print(auto_model.logModelInfo())\n",
    "    print(auto_model.explain())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MultinomialNB',\n",
       " 'LogisticRegression',\n",
       " 'KNeighborsClassifier',\n",
       " 'LinearSVC',\n",
       " 'DecisionTreeClassifierBaggingClassifier',\n",
       " 'AdaBoostClassifier',\n",
       " 'RandomForestClassifier',\n",
       " 'SGDClassifier']"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['MultinomialNB', 'LogisticRegression','KNeighborsClassifier','LinearSVC','DecisionTreeClassifier'\n",
    "'BaggingClassifier','AdaBoostClassifier','RandomForestClassifier','SGDClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voting Classifier (Ensemble Learning IV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "# 1) naive bias = mnb\n",
    "# 2) logistic regression =lr\n",
    "# 3) random forest =rf\n",
    "# 4) support vector machine = svm\n",
    "evc=VotingClassifier(estimators=[('mnb',mnb),('lr',lr),('rf',rf),('svm',svm)],voting='hard')\n",
    "evc.fit(x_train, y_train)\n",
    "print(\"score on test: \" + str(evc.score(x_test, y_test)))\n",
    "print(\"score on train: \"+ str(evc.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-907c6434866c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m rfr = RandomForestRegressor(\n\u001b[1;32m      5\u001b[0m     \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     max_features=random.choice(max_features))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Fill in rfr using your variables\n",
    "rfr = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=random.choice(max_depth),\n",
    "    min_samples_split=random.choice(min_samples_split),\n",
    "    max_features=random.choice(max_features))\n",
    "\n",
    "# Print out the parameters\n",
    "print(rfr.get_params())\n",
    "\n",
    "##################################################################\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# Finish the dictionary by adding the max_depth parameter\n",
    "param_dist = {\"max_depth\": [2,4,6,8],\n",
    "              \"max_features\": [2, 4, 6, 8, 10],\n",
    "              \"min_samples_split\": [2, 4, 8, 16]}\n",
    "\n",
    "# Create a random forest regression model\n",
    "rfr = RandomForestRegressor(n_estimators=10, random_state =1111)\n",
    "\n",
    "# Create a scorer to use (use the mean squared error)\n",
    "scorer = make_scorer(mean_squared_error)\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# Import the method for random search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Build a random search using param_dist, rfr, and scorer\n",
    "random_search =\\\n",
    "    RandomizedSearchCV(\n",
    "        estimator=rfr,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=10,\n",
    "        cv=5,\n",
    "        scoring=scorer)\n",
    "\n",
    "\n",
    "##################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "?LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/knn.csv')\n",
    "X = df.drop(['converted'], axis = 1) \n",
    "y = df['converted']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "> <ipython-input-381-ab92e3948bef>(28)<module>()->None\n",
      "-> breakpoint()\n",
      "(Pdb) exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-381-ab92e3948bef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_dist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   cv=5, n_iter=10, random_state=1111, refit=True)\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0moptimised_random_forest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'return'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_return\u001b[0;34m(self, frame, arg)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_returning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;31m# The user issued a 'next' or 'until' command.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoplineno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#rfc = RandomForestClassifier(n_estimators=100, random_state =1111)\n",
    "x = []\n",
    "for i in range(1,10,1):\n",
    "    x.append(i)\n",
    "\n",
    "y = []\n",
    "for i in range(50,200,50):\n",
    "\n",
    "    y.append(i)\n",
    "    \n",
    "\n",
    "param_dist = {\"max_depth\": x,\n",
    "              \"max_features\": x,\n",
    "              \"min_samples_split\": x,\n",
    "              'min_weight_fraction_leaf':[0,0.2,0.5],\n",
    "              'ccp_alpha':[0,0.2,0.5],\n",
    "             'n_estimators':y}\n",
    "\n",
    "\n",
    "\n",
    "# Finalize the random search\n",
    "rs = RandomizedSearchCV(\n",
    "  estimator=RandomForestClassifier(), param_distributions=param_dist,\n",
    "  cv=5, n_iter=10, random_state=1111, refit=True)\n",
    "rs.fit(X_train, y_train)\n",
    "optimised_random_forest = rs.best_estimator_\n",
    "# print the mean test scores:\n",
    "print('The accuracy for each run was: {}.'.format(rs.cv_results_['mean_test_score']))\n",
    "# print the best model score:\n",
    "print('The best accuracy for a single model was: {}'.format(rs.best_score_))\n",
    "print(rs.best_params_)\n",
    "#print(rs.get_params())\n",
    "print(optimised_random_forest.score(X_train, y_train))\n",
    "print(optimised_random_forest.score(X_test, y_test))\n",
    "print(optimised_random_forest.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(ccp_alpha=0, max_depth=4, max_features=7,\n",
       "                       min_samples_split=7, min_weight_fraction_leaf=0,\n",
       "                       n_estimators=50)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(estimator=RandomForestClassifier(), \n",
    "                    param_grid=param_dist,\n",
    "                    cv=3,\n",
    "                    refit=True,\n",
    "                    error_score=0,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "optimised_random_forest = clf.best_estimator_\n",
    "optimised_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=0, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'ccp_alpha': [0, 0.2, 0.5], 'max_depth': [1, 4, 7],\n",
       "                         'max_features': [1, 4, 7],\n",
       "                         'min_samples_split': [1, 4, 7],\n",
       "                         'min_weight_fraction_leaf': [0, 0.2, 0.5],\n",
       "                         'n_estimators': [50, 100, 150]})"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(estimator=RandomForestClassifier(), \n",
    "                    param_grid=param_dist,\n",
    "                    cv=3,\n",
    "                    refit=True,\n",
    "                    error_score=0,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8539325842696629\n",
      "0.8581460674157303\n"
     ]
    }
   ],
   "source": [
    "print(optimised_random_forest.score(X_train, y_train))\n",
    "print(clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc=RandomForestClassifier(max_depth=rs.best_params_.get('max_depth'),\\\n",
    "                           max_features=rs.best_params_.get('max_features'),\\\n",
    "                           min_samples_split=rs.best_params_.get('min_samples_split'),\\\n",
    "                           n_estimators=rs.best_params_.get('n_estimators'),\\\n",
    "                           min_weight_fraction_leaf=rs.best_params_.get('min_weight_fraction_leaf'),\\\n",
    "                           ccp_alpha=rs.best_params_.get('ccp_alpha'),\\\n",
    "                           random_state=1111)\\\n",
    ".fit(X_train, y_train)\n",
    "print(abc.score(X_train, y_train))\n",
    "print(abc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list expected at most 1 arguments, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-c8f86e66d2bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list expected at most 1 arguments, got 2"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "a=RandomForestClassifier(n_estimators=100).fit(X_test, y_test)\n",
    "\n",
    "print(list(X.columns, a.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "    param_grid = [\n",
    "        {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "        {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "]\n",
    "    forest_reg = RandomForestRegressor()\n",
    "    grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                               scoring='neg_mean_squared_error',\n",
    "                               return_train_score=True)\n",
    "    grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "... print(\"Scores:\", scores)\n",
    "... print(\"Mean:\", scores.mean())\n",
    "... print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "?KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "?RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "?RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
